{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2KNrV3VspLyD45klAfMB6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeongwoo22/ESAA_assignments/blob/main/OB_%EA%B3%BC%EC%A0%9C5_0925.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **앙상블 학습과 랜덤 포레스트**\n",
        "#### **핸즈온 머신러닝 - Chapter 7**"
      ],
      "metadata": {
        "id": "boIS5XW805vE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 앙상블 : 분류나 회귀 모델 같은 일련의 예측기\n",
        "- 앙상블 학습 : 예측기 학습\n",
        "- 앙상블 방법 : 앙상블 학습 알고리즘"
      ],
      "metadata": {
        "id": "GhNs6Ok0YFJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 랜덤 포레스트 : 예측을 하려면, 모든 개별 트리의 예측을 구하면 되는데, 결정 트리의 앙상블 ==> 간단한 방법이지만 오늘날 가장 강력한 머신러닝 알고리즘\n",
        "- 추가로, 이미 만든 여러 예측기들을 연결하면 더 좋은 예측기가 됨"
      ],
      "metadata": {
        "id": "K-jC61clYR_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.1 투표 기반 분류기**"
      ],
      "metadata": {
        "id": "M60wNEs11DFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 예시로 여러 분류기들을 훈련시킴\n",
        "- 로지스틱 회귀, SVM 분류기, 랜덤 포레스트 분류기 등\n",
        "- 더 좋은 분류기 만드는 방법 : 각 분류기의 예측을 모아 가장 많이 선택된 클래스를 예측 하는 것 \n",
        "- 직접 투표 : 앞처럼 다수결 투표로 정해지는 분류기"
      ],
      "metadata": {
        "id": "AbuHIgBQYudX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 약한 학습기가 여러개 모여 다양하면, 강한 학습기가 될 수 있다"
      ],
      "metadata": {
        "id": "ZrpTEsMjZNv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이서 셋 다운 => 5장에서 사용한 moons 데이터 셋\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "id": "mt90LHbDZ8IH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 여러 분류기를 조합하여 사이킷런의 투표 기반 분류기 만들기 \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "svm_clf = SVC(gamma=\"scale\", random_state=42)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
        "    voting='hard')"
      ],
      "metadata": {
        "id": "xJw008BZZQIV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 분류기의 테스트셋 정확도 확인\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtPrryjwZteE",
        "outputId": "925d62f2-c78c-4d98-ca23-c0232bf96e73"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.864\n",
            "RandomForestClassifier 0.896\n",
            "SVC 0.896\n",
            "VotingClassifier 0.912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 간접투표 : 개별 분류기의 예측을 평균내어 확률이 가장 높은 클래스를 예측한다 ==> 확률이 높은 투표에 비중을 더 두기 때문에 직접 투표 방식보다 성능이 더 높다"
      ],
      "metadata": {
        "id": "13DboavXa1pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.2 배깅과 페이스팅**"
      ],
      "metadata": {
        "id": "m4u5zgKR1PJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 배깅 : 훈련 세트에서 중복을 허용하여 샘플링하는 방식\n",
        "- 페이스팅 : 훈련세트에서 중복을 허용하지 않고 샘플링 하는 방식\n",
        "- 즉, 배깅과 페이스팅에서는 같은 훈련 샘플을 여러개의 예측기에 걸쳐 사용할 수 있는데, 배깅만이 한 예측기를 위해 같은 훈련 샘플을 여러 번 샘플링할 수 있다."
      ],
      "metadata": {
        "id": "x5Ri7Q9TbGCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 통계적 최빈값 : 모든 예측기가 훈련을 마치고, 앙상블이 모든 예측기의 예측을 모아서 새로운 샘플에 대한 예측을 만드는 것. 수집함수가 분류일 때"
      ],
      "metadata": {
        "id": "XhDrZ_N_bWhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.1 사이킷런의 배깅과 페이스팅"
      ],
      "metadata": {
        "id": "Rd7vLZMA1a1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,\n",
        "    max_samples=100, bootstrap=True, random_state=42)\n",
        "\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "oQpiJ1LGbnK2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.2 oob 평가"
      ],
      "metadata": {
        "id": "-F5LmDP11efS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators=500,\n",
        "    bootstrap=True, oob_score=True, random_state=40)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "\n",
        "bag_clf.oob_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_f-c4nsbu2b",
        "outputId": "730ac338-69f8-4e9a-abea-1de49f0d9c4b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8986666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf.oob_decision_function_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx0X5DqDb2HE",
        "outputId": "8ed8fa19-5e76-42f5-e1a2-6e805e357005"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.32275132, 0.67724868],\n",
              "       [0.34117647, 0.65882353],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.09497207, 0.90502793],\n",
              "       [0.31147541, 0.68852459],\n",
              "       [0.01754386, 0.98245614],\n",
              "       [0.97109827, 0.02890173],\n",
              "       [0.97765363, 0.02234637],\n",
              "       [0.74404762, 0.25595238],\n",
              "       [0.        , 1.        ],\n",
              "       [0.7173913 , 0.2826087 ],\n",
              "       [0.85026738, 0.14973262],\n",
              "       [0.97222222, 0.02777778],\n",
              "       [0.0625    , 0.9375    ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.97837838, 0.02162162],\n",
              "       [0.94642857, 0.05357143],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01704545, 0.98295455],\n",
              "       [0.39473684, 0.60526316],\n",
              "       [0.88700565, 0.11299435],\n",
              "       [1.        , 0.        ],\n",
              "       [0.97790055, 0.02209945],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99428571, 0.00571429],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.62569832, 0.37430168],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.13402062, 0.86597938],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.38251366, 0.61748634],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.27093596, 0.72906404],\n",
              "       [0.34146341, 0.65853659],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00531915, 0.99468085],\n",
              "       [0.98843931, 0.01156069],\n",
              "       [0.91428571, 0.08571429],\n",
              "       [0.97282609, 0.02717391],\n",
              "       [0.98019802, 0.01980198],\n",
              "       [0.        , 1.        ],\n",
              "       [0.07361963, 0.92638037],\n",
              "       [0.98019802, 0.01980198],\n",
              "       [0.0052356 , 0.9947644 ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.97790055, 0.02209945],\n",
              "       [0.8       , 0.2       ],\n",
              "       [0.42424242, 0.57575758],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.66477273, 0.33522727],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.86781609, 0.13218391],\n",
              "       [1.        , 0.        ],\n",
              "       [0.56725146, 0.43274854],\n",
              "       [0.1576087 , 0.8423913 ],\n",
              "       [0.66492147, 0.33507853],\n",
              "       [0.91709845, 0.08290155],\n",
              "       [0.        , 1.        ],\n",
              "       [0.16759777, 0.83240223],\n",
              "       [0.87434555, 0.12565445],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.995     , 0.005     ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.07878788, 0.92121212],\n",
              "       [0.05418719, 0.94581281],\n",
              "       [0.29015544, 0.70984456],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.83040936, 0.16959064],\n",
              "       [0.01092896, 0.98907104],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.21465969, 0.78534031],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.94660194, 0.05339806],\n",
              "       [0.77094972, 0.22905028],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.16574586, 0.83425414],\n",
              "       [0.65306122, 0.34693878],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02564103, 0.97435897],\n",
              "       [0.50555556, 0.49444444],\n",
              "       [1.        , 0.        ],\n",
              "       [0.03208556, 0.96791444],\n",
              "       [0.99435028, 0.00564972],\n",
              "       [0.23699422, 0.76300578],\n",
              "       [0.49509804, 0.50490196],\n",
              "       [0.9947644 , 0.0052356 ],\n",
              "       [0.00555556, 0.99444444],\n",
              "       [0.98963731, 0.01036269],\n",
              "       [0.26153846, 0.73846154],\n",
              "       [0.92972973, 0.07027027],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.80113636, 0.19886364],\n",
              "       [1.        , 0.        ],\n",
              "       [0.0106383 , 0.9893617 ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98181818, 0.01818182],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01036269, 0.98963731],\n",
              "       [0.97752809, 0.02247191],\n",
              "       [0.99453552, 0.00546448],\n",
              "       [0.01960784, 0.98039216],\n",
              "       [0.17857143, 0.82142857],\n",
              "       [0.98387097, 0.01612903],\n",
              "       [0.29533679, 0.70466321],\n",
              "       [0.98295455, 0.01704545],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00561798, 0.99438202],\n",
              "       [0.75690608, 0.24309392],\n",
              "       [0.38624339, 0.61375661],\n",
              "       [0.40625   , 0.59375   ],\n",
              "       [0.87368421, 0.12631579],\n",
              "       [0.92462312, 0.07537688],\n",
              "       [0.05181347, 0.94818653],\n",
              "       [0.82802548, 0.17197452],\n",
              "       [0.01546392, 0.98453608],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02298851, 0.97701149],\n",
              "       [0.9726776 , 0.0273224 ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01041667, 0.98958333],\n",
              "       [0.        , 1.        ],\n",
              "       [0.03804348, 0.96195652],\n",
              "       [0.02040816, 0.97959184],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.94915254, 0.05084746],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.99462366, 0.00537634],\n",
              "       [0.        , 1.        ],\n",
              "       [0.39378238, 0.60621762],\n",
              "       [0.33152174, 0.66847826],\n",
              "       [0.00609756, 0.99390244],\n",
              "       [0.        , 1.        ],\n",
              "       [0.3172043 , 0.6827957 ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00588235, 0.99411765],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98924731, 0.01075269],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.62893082, 0.37106918],\n",
              "       [0.92344498, 0.07655502],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99526066, 0.00473934],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98888889, 0.01111111],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.06989247, 0.93010753],\n",
              "       [1.        , 0.        ],\n",
              "       [0.03608247, 0.96391753],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02185792, 0.97814208],\n",
              "       [1.        , 0.        ],\n",
              "       [0.95808383, 0.04191617],\n",
              "       [0.78362573, 0.21637427],\n",
              "       [0.56650246, 0.43349754],\n",
              "       [0.        , 1.        ],\n",
              "       [0.18023256, 0.81976744],\n",
              "       [1.        , 0.        ],\n",
              "       [0.93121693, 0.06878307],\n",
              "       [0.97175141, 0.02824859],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00531915, 0.99468085],\n",
              "       [0.        , 1.        ],\n",
              "       [0.43010753, 0.56989247],\n",
              "       [0.85858586, 0.14141414],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00558659, 0.99441341],\n",
              "       [0.        , 1.        ],\n",
              "       [0.96923077, 0.03076923],\n",
              "       [0.        , 1.        ],\n",
              "       [0.21649485, 0.78350515],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98477157, 0.01522843],\n",
              "       [0.8       , 0.2       ],\n",
              "       [0.99441341, 0.00558659],\n",
              "       [0.        , 1.        ],\n",
              "       [0.09497207, 0.90502793],\n",
              "       [0.99492386, 0.00507614],\n",
              "       [0.01714286, 0.98285714],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02747253, 0.97252747],\n",
              "       [1.        , 0.        ],\n",
              "       [0.77005348, 0.22994652],\n",
              "       [0.        , 1.        ],\n",
              "       [0.90229885, 0.09770115],\n",
              "       [0.98387097, 0.01612903],\n",
              "       [0.22222222, 0.77777778],\n",
              "       [0.20348837, 0.79651163],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.20338983, 0.79661017],\n",
              "       [0.98181818, 0.01818182],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98969072, 0.01030928],\n",
              "       [0.        , 1.        ],\n",
              "       [0.48663102, 0.51336898],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00529101, 0.99470899],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.08379888, 0.91620112],\n",
              "       [0.12352941, 0.87647059],\n",
              "       [0.99415205, 0.00584795],\n",
              "       [0.03517588, 0.96482412],\n",
              "       [1.        , 0.        ],\n",
              "       [0.39790576, 0.60209424],\n",
              "       [0.05434783, 0.94565217],\n",
              "       [0.53191489, 0.46808511],\n",
              "       [0.51898734, 0.48101266],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.60869565, 0.39130435],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.24157303, 0.75842697],\n",
              "       [0.81578947, 0.18421053],\n",
              "       [0.08717949, 0.91282051],\n",
              "       [0.99453552, 0.00546448],\n",
              "       [0.82142857, 0.17857143],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.11904762, 0.88095238],\n",
              "       [0.04188482, 0.95811518],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.89150943, 0.10849057],\n",
              "       [0.19230769, 0.80769231],\n",
              "       [0.95238095, 0.04761905],\n",
              "       [0.00515464, 0.99484536],\n",
              "       [0.59375   , 0.40625   ],\n",
              "       [0.07692308, 0.92307692],\n",
              "       [0.99484536, 0.00515464],\n",
              "       [0.83684211, 0.16315789],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99484536, 0.00515464],\n",
              "       [0.95360825, 0.04639175],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.26395939, 0.73604061],\n",
              "       [0.98461538, 0.01538462],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00574713, 0.99425287],\n",
              "       [0.85142857, 0.14857143],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.75301205, 0.24698795],\n",
              "       [0.8969697 , 0.1030303 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.75555556, 0.24444444],\n",
              "       [0.48863636, 0.51136364],\n",
              "       [0.        , 1.        ],\n",
              "       [0.92473118, 0.07526882],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.87709497, 0.12290503],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.74752475, 0.25247525],\n",
              "       [0.09146341, 0.90853659],\n",
              "       [0.42268041, 0.57731959],\n",
              "       [0.22395833, 0.77604167],\n",
              "       [0.        , 1.        ],\n",
              "       [0.87046632, 0.12953368],\n",
              "       [0.78212291, 0.21787709],\n",
              "       [0.00507614, 0.99492386],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02884615, 0.97115385],\n",
              "       [0.96      , 0.04      ],\n",
              "       [0.93478261, 0.06521739],\n",
              "       [1.        , 0.        ],\n",
              "       [0.50731707, 0.49268293],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01604278, 0.98395722],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.96987952, 0.03012048],\n",
              "       [0.        , 1.        ],\n",
              "       [0.05172414, 0.94827586],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99494949, 0.00505051],\n",
              "       [0.01675978, 0.98324022],\n",
              "       [1.        , 0.        ],\n",
              "       [0.14583333, 0.85416667],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00546448, 0.99453552],\n",
              "       [0.        , 1.        ],\n",
              "       [0.41836735, 0.58163265],\n",
              "       [0.13095238, 0.86904762],\n",
              "       [0.22110553, 0.77889447],\n",
              "       [1.        , 0.        ],\n",
              "       [0.97647059, 0.02352941],\n",
              "       [0.21195652, 0.78804348],\n",
              "       [0.98882682, 0.01117318],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.96428571, 0.03571429],\n",
              "       [0.34554974, 0.65445026],\n",
              "       [0.98235294, 0.01764706],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99465241, 0.00534759],\n",
              "       [0.        , 1.        ],\n",
              "       [0.06043956, 0.93956044],\n",
              "       [0.98214286, 0.01785714],\n",
              "       [1.        , 0.        ],\n",
              "       [0.03108808, 0.96891192],\n",
              "       [0.58854167, 0.41145833]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.3 랜덤 패치와 랜덤 서브스페이스**"
      ],
      "metadata": {
        "id": "b61sB2W51TBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 랜덤 패치 방식 : 훈련 특성과 샘플을 모두 샘플링하는 것\n",
        "- 랜덤 서브스페이스 방식 : 훈련 샘플을 모두 사용하고 피처는 샘플링하는 것"
      ],
      "metadata": {
        "id": "Y9DQHgKcb64A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.4 랜덤 포레스트**"
      ],
      "metadata": {
        "id": "tGl8WBhC1V4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 랜덤 포레스트 : 일반적으로 배깅 방법(또는 페이스팅)을 적용한 결정 트리의 앙상블이다."
      ],
      "metadata": {
        "id": "RjIhwVJtFwY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 500개의 트리로 이루어진 랜덤 포레스트 모델\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "60K8RRf_F1zH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BaggingClassifier를 사용해 만든 랜덤 포레스트 모델\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16),\n",
        "    n_estimators=500, random_state=42)\n",
        "\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "_-fBSel9F7Pf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4.1 엑스트라 트리"
      ],
      "metadata": {
        "id": "L6Fh_OCE1lHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 익스트림 랜덤 트리(extremely randomized trees) : 극단적으로 무작위한 트리의 랜덤 포레스트"
      ],
      "metadata": {
        "id": "xf2Pt_TmGE_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4.2 특성 중요도"
      ],
      "metadata": {
        "id": "UBX_kRQw1nx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- feature_importances_ : 사이킷런은 훈련이 끝난 뒤 자동으로 이 점수를 계산하고 중요도의 전체 합이 1이 되도록 결과값을 정규화"
      ],
      "metadata": {
        "id": "nFBGGW_bGLbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# import data\n",
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "sJDRO3vYGUg_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model fitting\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
        "rnd_clf.fit(iris[\"data\"], iris[\"target\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi9auc_BGWPs",
        "outputId": "0f705911-53e9-43d9-8aca-5c1a7d087ae1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=500, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the importances of features\n",
        "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
        "    print(name, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KenG7n-4GYE1",
        "outputId": "00dc3ed6-ff9c-4585-95b4-85caaf22cb1f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) 0.11249225099876375\n",
            "sepal width (cm) 0.02311928828251033\n",
            "petal length (cm) 0.4410304643639577\n",
            "petal width (cm) 0.4233579963547682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.5 부스팅**"
      ],
      "metadata": {
        "id": "V_vFNE451qpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5.1 에이다부스트"
      ],
      "metadata": {
        "id": "O8R5qrI91u3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 부스팅(boosting) : 약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법"
      ],
      "metadata": {
        "id": "oBqLjlPaGZqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 에이다부스트 : 예측기를 보완하는 새로운 예측기를 만드는 방법은 이전 모델이 과소적합했던 훈련 샘플의 가중치를 더 높이는 것 ==> 새로운 예측기는 학습하기 어려운 샘플에 점점 더 맞춰지게 되는데 이게 에이다부스트"
      ],
      "metadata": {
        "id": "sbx7LFqiGeqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
        "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx0Jppu4Grlu",
        "outputId": "dd729176-9f69-4871-8496-8c47e3c943d6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
              "                   learning_rate=0.5, n_estimators=200, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5.2 그레이디언트 부스팅"
      ],
      "metadata": {
        "id": "FlL-x9DW1xv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 그레디언트 부스팅(gradient boosting) : 에이다부스트처럼 앙상블에 이전까지의 오차를 보정하도록 예측 모델을 순차적으로 추가"
      ],
      "metadata": {
        "id": "xMWr_389GuHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model fitting : DecisionTreeRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg1.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZHgMcDTG1Ak",
        "outputId": "f64cf098-f0aa-4946-da64-c976586763b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2 = y - tree_reg1.predict(X) # 잔차\n",
        "\n",
        "# 두 번째 DecisionTreeRegressor 학습\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg2.fit(X, y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svjqI58iG2Zu",
        "outputId": "a457c639-cbe0-425a-fea0-19c23412ced2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y3 = y - tree_reg2.predict(X) # 잔차\n",
        "\n",
        "# 세 번째 DecisionTreeRegressor 학습\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg3.fit(X, y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSsqz2lTG5DQ",
        "outputId": "04bba8ff-f8ea-42aa-ab55-db7ba6140404"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import package and split data\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=49)"
      ],
      "metadata": {
        "id": "_PGblBHOHKiW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.6 스태킹**"
      ],
      "metadata": {
        "id": "ENjeJQ_M2Kry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 스태킹(stacking) : 앙상블에 속한 모든 예측 모델의 예측을 취합하는 모델"
      ],
      "metadata": {
        "id": "zNJwmElaHZS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 메타 학습기(meta learner) 혹은 블렌더(blender)는 각 모델의 예측을 입력 받아 최종 예측을 한다."
      ],
      "metadata": {
        "id": "Nd-v1VqdHeSx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lNqDKc3D2LtG"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}